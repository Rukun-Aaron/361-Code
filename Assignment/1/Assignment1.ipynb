{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 Coding Decision Tree:\n",
    "\n",
    "### Spliting the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from treelib import Node, Tree\n",
    "df = pd.read_csv(\"agaricus-lepiota.data\", header = None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding columns to the dataframe and splitting it into training and testing sets\n",
    " We also remove the entries with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df.columns = ['class', 'cap_shape', 'cap_surface', 'cap_color', 'bruises', 'odor', \n",
    "               'gill_attachment', 'gill_spacing', 'gill_size', 'gill_color', \n",
    "               'stalk_shape', 'stalk_root', 'stalk_surface_above_ring', 'stalk_surface_below_ring', 'stalk_color_above_ring', 'stalk_color_below_ring', \n",
    "               'veil_type', 'veil_color', 'ring_number', 'ring_type', 'spore_print_color', 'population', 'habitat']\n",
    "\n",
    "df = df.drop(df[df.stalk_root  == \"?\"].index) # drop rows with missing values\n",
    "\n",
    "training, testing = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The methods used to generate the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entropy(target_col):\n",
    "        elements,counts = np.unique(target_col,return_counts = True)\n",
    "        entropy = 0\n",
    "        for i in range(len(elements) ):\n",
    "             entropy +=(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts))\n",
    "        return entropy\n",
    "\n",
    "def information_Gain(data,split_feature, target_col=\"class\"):\n",
    "        total_entropy = entropy(data[target_col])\n",
    "        vals,counts= np.unique(data[split_feature],return_counts=True)\n",
    "        weighted_entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_feature]==vals[i]).dropna()[target_col]) for i in range(len(vals))])\n",
    "        information_gain = total_entropy - weighted_entropy\n",
    "        return information_gain\n",
    "\n",
    "def build_tree(data,features, target_col=\"class\",parent_node_value = None,depth=-1, stopping_depth=3, tree =None):\n",
    "        \n",
    "        if len(np.unique(data[target_col])) <= 1 or depth == stopping_depth :\n",
    "            \n",
    "            value = np.unique(data[target_col])[0]\n",
    "            tree.create_node(value , identifier=len(tree.all_nodes())+1, parent=parent_node_value)\n",
    "            return tree\n",
    "           \n",
    "        elif len(data) == 0:\n",
    "            node_Value = np.unique(data[target_col])[np.argmax(np.unique(data[target_col],return_counts=True)[1])]\n",
    "\n",
    "            tree.create_node(node_Value, node_Value, parent=parent_node_value)\n",
    "            return tree\n",
    "        \n",
    "        elif len(features) ==0:\n",
    "            \n",
    "            return tree \n",
    "            \n",
    "        else:\n",
    "            \n",
    "\n",
    "            information_Gain_List =[]\n",
    "\n",
    "            for feature in features:\n",
    "                    information_Gain_List.append(information_Gain(data,feature))\n",
    "            \n",
    "            best_feature_index = np.argmax(information_Gain_List)\n",
    "            best_feature = features[best_feature_index]\n",
    "            \n",
    "          \n",
    "            if tree is None:\n",
    "                decision_tree = Tree()\n",
    "                decision_tree.create_node(tag=best_feature, identifier=best_feature, parent=None)\n",
    "            else:\n",
    "                decision_tree = tree\n",
    "                decision_tree.create_node(tag=best_feature, identifier=best_feature , parent=parent_node_value)\n",
    "            \n",
    "            features = features.drop(best_feature)\n",
    "           \n",
    "            depth += 1\n",
    "            for value in np.unique(data[best_feature]):\n",
    "                \n",
    "                sub_data = data.where(data[best_feature] == value).dropna()\n",
    "                identifier = str(best_feature) + \"_\" + str(value)\n",
    "                decision_tree.create_node(tag=value, identifier=identifier, parent=best_feature)\n",
    "                build_tree(sub_data,features,target_col,identifier, depth, stopping_depth, decision_tree)\n",
    "                \n",
    "          \n",
    "            return(decision_tree) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Resulting Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odor\n",
      "├── a\n",
      "│   └── e\n",
      "├── c\n",
      "│   └── p\n",
      "├── f\n",
      "│   └── p\n",
      "├── l\n",
      "│   └── e\n",
      "├── m\n",
      "│   └── p\n",
      "├── n\n",
      "│   └── spore_print_color\n",
      "│       ├── k\n",
      "│       │   └── e\n",
      "│       ├── n\n",
      "│       │   └── e\n",
      "│       ├── r\n",
      "│       │   └── p\n",
      "│       └── w\n",
      "│           └── cap_color\n",
      "│               ├── c\n",
      "│               │   └── e\n",
      "│               ├── g\n",
      "│               │   └── e\n",
      "│               ├── n\n",
      "│               │   └── e\n",
      "│               ├── p\n",
      "│               │   └── e\n",
      "│               ├── w\n",
      "│               │   └── p\n",
      "│               └── y\n",
      "│                   └── p\n",
      "└── p\n",
      "    └── p\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_Tree = build_tree(training, training.columns[1:], stopping_depth = np.inf)\n",
    "decision_Tree.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above decision tre is generated when there is no stopping depth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following trees are generated when the stopping depth is set to 1,2,3,4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree with depth 1:\n",
      "odor\n",
      "├── a\n",
      "│   └── e\n",
      "├── c\n",
      "│   └── p\n",
      "├── f\n",
      "│   └── p\n",
      "├── l\n",
      "│   └── e\n",
      "├── m\n",
      "│   └── p\n",
      "├── n\n",
      "│   └── spore_print_color\n",
      "│       ├── k\n",
      "│       │   └── e\n",
      "│       ├── n\n",
      "│       │   └── e\n",
      "│       ├── r\n",
      "│       │   └── p\n",
      "│       └── w\n",
      "│           └── e\n",
      "└── p\n",
      "    └── p\n",
      "\n",
      "DecisionTree with depth 2:\n",
      "odor\n",
      "├── a\n",
      "│   └── e\n",
      "├── c\n",
      "│   └── p\n",
      "├── f\n",
      "│   └── p\n",
      "├── l\n",
      "│   └── e\n",
      "├── m\n",
      "│   └── p\n",
      "├── n\n",
      "│   └── spore_print_color\n",
      "│       ├── k\n",
      "│       │   └── e\n",
      "│       ├── n\n",
      "│       │   └── e\n",
      "│       ├── r\n",
      "│       │   └── p\n",
      "│       └── w\n",
      "│           └── cap_color\n",
      "│               ├── c\n",
      "│               │   └── e\n",
      "│               ├── g\n",
      "│               │   └── e\n",
      "│               ├── n\n",
      "│               │   └── e\n",
      "│               ├── p\n",
      "│               │   └── e\n",
      "│               ├── w\n",
      "│               │   └── p\n",
      "│               └── y\n",
      "│                   └── p\n",
      "└── p\n",
      "    └── p\n",
      "\n",
      "DecisionTree with depth 3:\n",
      "odor\n",
      "├── a\n",
      "│   └── e\n",
      "├── c\n",
      "│   └── p\n",
      "├── f\n",
      "│   └── p\n",
      "├── l\n",
      "│   └── e\n",
      "├── m\n",
      "│   └── p\n",
      "├── n\n",
      "│   └── spore_print_color\n",
      "│       ├── k\n",
      "│       │   └── e\n",
      "│       ├── n\n",
      "│       │   └── e\n",
      "│       ├── r\n",
      "│       │   └── p\n",
      "│       └── w\n",
      "│           └── cap_color\n",
      "│               ├── c\n",
      "│               │   └── e\n",
      "│               ├── g\n",
      "│               │   └── e\n",
      "│               ├── n\n",
      "│               │   └── e\n",
      "│               ├── p\n",
      "│               │   └── e\n",
      "│               ├── w\n",
      "│               │   └── p\n",
      "│               └── y\n",
      "│                   └── p\n",
      "└── p\n",
      "    └── p\n",
      "\n",
      "DecisionTree with depth 4:\n",
      "odor\n",
      "├── a\n",
      "│   └── e\n",
      "├── c\n",
      "│   └── p\n",
      "├── f\n",
      "│   └── p\n",
      "├── l\n",
      "│   └── e\n",
      "├── m\n",
      "│   └── p\n",
      "├── n\n",
      "│   └── spore_print_color\n",
      "│       ├── k\n",
      "│       │   └── e\n",
      "│       ├── n\n",
      "│       │   └── e\n",
      "│       ├── r\n",
      "│       │   └── p\n",
      "│       └── w\n",
      "│           └── cap_color\n",
      "│               ├── c\n",
      "│               │   └── e\n",
      "│               ├── g\n",
      "│               │   └── e\n",
      "│               ├── n\n",
      "│               │   └── e\n",
      "│               ├── p\n",
      "│               │   └── e\n",
      "│               ├── w\n",
      "│               │   └── p\n",
      "│               └── y\n",
      "│                   └── p\n",
      "└── p\n",
      "    └── p\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_Tree_depth_1 = build_tree(training, training.columns[1:], stopping_depth = 1)\n",
    "decision_Tree_depth_2 = build_tree(training, training.columns[1:], stopping_depth = 2)\n",
    "decision_Tree_depth_3 = build_tree(training, training.columns[1:], stopping_depth = 3)\n",
    "decision_Tree_depth_4 = build_tree(training, training.columns[1:], stopping_depth = 4)\n",
    "\n",
    "print(\"DecisionTree with depth 1:\")\n",
    "decision_Tree_depth_1.show()\n",
    "\n",
    "print(\"DecisionTree with depth 2:\")\n",
    "decision_Tree_depth_2.show()\n",
    "\n",
    "print(\"DecisionTree with depth 3:\")\n",
    "decision_Tree_depth_3.show()\n",
    "\n",
    "print(\"DecisionTree with depth 4:\")\n",
    "decision_Tree_depth_4.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, tree):  \n",
    "    \n",
    "    node = tree.get_node(tree.root)\n",
    "    while not node.is_leaf():\n",
    "        \n",
    "        feature = node.tag \n",
    "        value = df[feature]\n",
    "        \n",
    "        tree_feature = tree.get_node(feature + \"_\" + value)\n",
    "        children = tree.children(tree_feature.identifier)\n",
    "        if (children[0].is_leaf()):\n",
    "             return children[0].tag\n",
    "        else:\n",
    "             \n",
    "            node = children[0]\n",
    "         \n",
    "\n",
    "def accuracy(df, tree):\n",
    "    correct = 0\n",
    "    for i in range(len(df)):\n",
    "        predicted = predict(df.iloc[i], tree)\n",
    "        ground_truth = df.iloc[i][\"class\"]\n",
    "        if predicted == ground_truth:\n",
    "            correct += 1\n",
    "       \n",
    "    return np.divide(correct,len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(accuracy (testing, x))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
