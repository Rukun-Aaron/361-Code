{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from treelib import Node, Tree\n",
    "df = pd.read_csv(\"agaricus-lepiota.data\", header = None)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df.columns = ['class', 'cap_shape', 'cap_surface', 'cap_color', 'bruises', 'odor', \n",
    "               'gill_attachment', 'gill_spacing', 'gill_size', 'gill_color', \n",
    "               'stalk_shape', 'stalk_root', 'stalk_surface_above_ring', 'stalk_surface_below_ring', 'stalk_color_above_ring', 'stalk_color_below_ring', \n",
    "               'veil_type', 'veil_color', 'ring_number', 'ring_type', 'spore_print_color', 'population', 'habitat']\n",
    "df = df.drop(df[df.stalk_root  == \"?\"].index)\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "\n",
    "# train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "training, testing = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# elements, counts = np.unique(df['odor'], return_counts = True)\n",
    "# print(elements, counts)\n",
    "\n",
    "\n",
    "# train_X.drop(['cap_color','odor'], axis= 1)\n",
    "# train_X.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedNode():\n",
    "    \"\"\"\n",
    "    A class to represent a node in a decision tree\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=None, left=None, right=None, value=None):\n",
    "        \"\"\"\n",
    "        Initialize a node\n",
    "        \n",
    "        Parameters:\n",
    "        feature (int): Index of the feature used to split the data\n",
    "        threshold (float): Threshold value used to split the data\n",
    "        left (Node): Left child node\n",
    "        right (Node): Right child node\n",
    "        value (float): Predicted value for the node\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        self.children = []\n",
    "        super().__init__( identifier=value)\n",
    "         \n",
    "    def add_child(self, node):\n",
    "        self.children.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 51)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m51\u001b[0m\n\u001b[1;33m    vals,counts= np.unique(data[split_attribute_name],return_counts=True)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class DecisionTree(Tree):\n",
    "    \"\"\"\n",
    "    A class to represent a decision tree\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        \"\"\"\n",
    "        Initialize a decision tree\n",
    "        \n",
    "        Parameters:\n",
    "        max_depth (int): Maximum depth of the tree\n",
    "        min_samples_split (int): Minimum number of samples required to split a node\n",
    "        \"\"\"\n",
    "        self.depth = -1\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        super().__init__()\n",
    "\n",
    "   \n",
    "        \n",
    "\n",
    "    def entropy(self, target_col):\n",
    "        # elements, counts = np.unique(target_col, return_counts = True)\n",
    "        # entropy = 0\n",
    "\n",
    "        # for i in range(len(elements)):\n",
    "        #    if counts[i] >0:\n",
    "        #     p = counts[i]/ np.sum(counts)\n",
    "        #     entropy += -p * np.log2(p)\n",
    "        # return entropy\n",
    "        elements,counts = np.unique(target_col,return_counts = True)\n",
    "        entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
    "        return entropy\n",
    "        \n",
    "    def information_Gain(self, data,split_feature, target_col=\"class\"):\n",
    "        # total_entropy = self.entropy(data[target_col])\n",
    "\n",
    "        # value, counts = np.unique(data[split_feature], return_counts = True)\n",
    "        # weighted_entropy = 0\n",
    "        # for i in range(len(value)):\n",
    "\n",
    "        #     if counts[i] >0:\n",
    "        #         p = counts[i]/ np.sum(counts)\n",
    "\n",
    "        #         weighted_entropy += p * self.entropy(data.where(data[split_feature] == value[i]).dropna()[target_col])\n",
    "\n",
    "        # information_gain = total_entropy - weighted_entropy\n",
    "        # return information_gain\n",
    "         total_entropy = entropy(data[target_name])\n",
    "\n",
    "        #Calculate the values and the corresponding counts for the split attribute \n",
    "        vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
    "        \n",
    "        #Calculate the weighted entropy\n",
    "        Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
    "        \n",
    "        #Calculate the information gain\n",
    "        Information_Gain = total_entropy - Weighted_Entropy\n",
    "        return Information_Gain\n",
    "\n",
    "\n",
    "    def build_tree(self, data,original_data,features, target_col =\"class\", parent_node_value = None,):\n",
    "         \n",
    "        if len(np.unique(data[target_col])) <= 1 or self.depth == self.max_depth:\n",
    "            node_Value = np.unique(data[target_col])[0]\n",
    "            return Node( node_Value )\n",
    "\n",
    "        elif len(data) == 0:\n",
    "            node_Value = np.unique(original_data[target_col])[np.argmax(np.unique(original_data[target_col],return_counts=True)[1])]\n",
    "            return Node( node_Value)\n",
    "        elif len(features) ==0:\n",
    "            return Node(parent_node_value)\n",
    "\n",
    "        else:\n",
    "\n",
    "            parent_node_value = np.unique(data[target_col])[np.argmax(np.unique(data[target_col],return_counts=True)[1])]\n",
    "\n",
    "            information_Gain_List =[]\n",
    "\n",
    "            for feature in features[1:]:\n",
    "                    information_Gain_List.append(self.information_Gain(data,feature))\n",
    "            \n",
    "            best_feature_index = np.argmax(information_Gain_List)\n",
    "            best_feature = features[best_feature_index]\n",
    "\n",
    "\n",
    "            #  = Tree()\n",
    "            self.create_node(best_feature, best_feature)\n",
    "            # self.create_node(node)\n",
    "            sub_features = features.drop(best_feature)\n",
    "            self.depth +=1\n",
    "            print(best_feature)\n",
    "\n",
    "            for value in np.unique(data[best_feature]):\n",
    "                print(value)\n",
    "                sub_data = data.where(data[best_feature] == value).dropna()\n",
    "\n",
    "                sub_tree = self.build_tree(sub_data,original_data,sub_features,target_col,parent_node_value)\n",
    "\n",
    "                self.paste(value, sub_tree)\n",
    "            return tree\n",
    "\n",
    "        # get best feature, create that node, then iterate through all the values of that feature and create a new node for each value. \n",
    "        # Then, for each value, create a new data set that has all the rows where the feature value is equal to the value of the node. \n",
    "        # Then, recursively call this function on the new data set and the new node.\n",
    "        \n",
    "tree = DecisionTree(max_depth= 3)\n",
    "tree.build_tree(training, training, training.columns[1:])\n",
    "tree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rukun\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rukun\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rukun\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'class'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15768\\2328011593.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15768\\3428532771.py\u001b[0m in \u001b[0;36mbuild_tree\u001b[1;34m(self, data, original_data, features, target_col, parent_node_value)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moriginal_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_col\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent_node_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mnode_Value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNode\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnode_Value\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rukun\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rukun\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'class'"
     ]
    }
   ],
   "source": [
    "tree = DecisionTree(max_depth= 3)\n",
    "tree.build_tree(train_X, train_X, train_X.columns[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
